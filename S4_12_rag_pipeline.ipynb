{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full RAG Pipeline (Retrieval-Augmented Generation)\n",
    "\n",
    "## ğŸ¯ Bu Kodun AmacÄ±\n",
    "Tam bir RAG sistemi kurmak: DokÃ¼man â†’ Embedding â†’ VectorStore â†’ Retrieval â†’ Generation.\n",
    "\n",
    "## Ne YapacaÄŸÄ±z?\n",
    "- PDF dokÃ¼manÄ± yÃ¼kleyip chunking yapacaÄŸÄ±z\n",
    "- **HuggingFace Embeddings** ile metinleri vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz\n",
    "- **ChromaDB** ile vector database oluÅŸturacaÄŸÄ±z\n",
    "- **Retriever** ile soruya en uygun chunk'larÄ± bulacaÄŸÄ±z\n",
    "- **RAG Chain** ile context'i LLM'e gÃ¶ndereceÄŸiz\n",
    "- Test sorularÄ± ile sistemin akademik makaleden cevap Ã¼retmesini gÃ¶receÄŸiz\n",
    "\n",
    "## Ã‡alÄ±ÅŸtÄ±rma\n",
    "Kod Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda tam bir RAG pipeline kurulur ve \"Attention is All You Need\" makalesi hakkÄ±nda sorular sorulur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Gerekli KÃ¼tÃ¼phaneleri Ä°Ã§e Aktarma\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- RAG sistemi iÃ§in gerekli tÃ¼m LangChain bileÅŸenlerini yÃ¼klÃ¼yoruz\n",
    "- Groq LLM, PDF okuyucu, chunking aracÄ±, embedding modeli ve vektÃ¶r veritabanÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG PIPELINE KURULUMU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"RAG PIPELINE KURULUMU\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ AdÄ±m 1/6: PDF DokÃ¼manÄ±nÄ± YÃ¼kleme\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- \"Attention is All You Need\" makalesini PyPDFLoader ile yÃ¼klÃ¼yoruz\n",
    "- Her sayfa ayrÄ± bir Document objesi olarak yÃ¼klenir\n",
    "- Her Document: `page_content` (metin) + `metadata` (sayfa no, kaynak) iÃ§erir\n",
    "\n",
    "**SonuÃ§:** 15 sayfalÄ±k PDF â†’ 15 Document objesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] DÃ¶kÃ¼man yÃ¼kleniyor...\n",
      "      15 sayfa yÃ¼klendi\n"
     ]
    }
   ],
   "source": [
    "print(\"[1/6] DÃ¶kÃ¼man yÃ¼kleniyor...\")\n",
    "loader = PyPDFLoader(\"attention_is_all_you_need.pdf\")\n",
    "documents = loader.load()\n",
    "print(f\"      {len(documents)} sayfa yÃ¼klendi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ AdÄ±m 2/6: Metni ParÃ§alara AyÄ±rma (Chunking)\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- Uzun metinleri **1000 karakterlik** parÃ§alara bÃ¶lÃ¼yoruz\n",
    "- **100 karakter overlap** (Ã¶rtÃ¼ÅŸme) kullanÄ±yoruz\n",
    "\n",
    "**Neden?**\n",
    "- LLM'ler ve embedding modelleri sÄ±nÄ±rlÄ± boyutla Ã§alÄ±ÅŸÄ±r\n",
    "- Overlap sayesinde cÃ¼mleler kesilmez, context korunur\n",
    "\n",
    "**chunk_size=1000:** Her parÃ§a maksimum 1000 karakter\n",
    "**chunk_overlap=100:** Yan yana chunk'lar arasÄ±nda 100 karakter ortak alan\n",
    "\n",
    "**Ã–rnek:**\n",
    "- Chunk 1: [0-1000]\n",
    "- Chunk 2: [900-1900] â† 100 karakterlik overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/6] Chunking iÅŸlemi...\n",
      "      49 chunk oluÅŸturuldu\n"
     ]
    }
   ],
   "source": [
    "print(\"[2/6] Chunking iÅŸlemi...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"      {len(chunks)} chunk oluÅŸturuldu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§® AdÄ±m 3/6: Embedding Modelini YÃ¼kleme\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- Metinleri **sayÄ±sal vektÃ¶rlere** Ã§eviren bir model yÃ¼klÃ¼yoruz\n",
    "- Model: sentence-transformers/all-MiniLM-L6-v2 (384 boyutlu vektÃ¶r)\n",
    "\n",
    "**Embedding nedir?**\n",
    "- Her metin â†’ 384 uzunluÄŸunda bir sayÄ± dizisi\n",
    "- Anlamca benzer metinler â†’ benzer vektÃ¶rler\n",
    "- Ã–rnek: \n",
    "  - \"AI gÃ¼Ã§lÃ¼\" â†’ [0.2, 0.8, 0.1, ...]\n",
    "  - \"Yapay zeka kuvvetli\" â†’ [0.19, 0.82, 0.09, ...] â† Ã§ok benzer!\n",
    "\n",
    "**Bu sayede:** Semantik (anlamsal) benzerlik hesaplayabiliriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/6] Embedding modeli yÃ¼kleniyor...\n",
      "      Embedding modeli hazÄ±r\n"
     ]
    }
   ],
   "source": [
    "print(\"[3/6] Embedding modeli yÃ¼kleniyor...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "print(\"      Embedding modeli hazÄ±r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ AdÄ±m 4/6: VektÃ¶r VeritabanÄ± OluÅŸturma (ChromaDB)\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- TÃ¼m chunk'larÄ± embedding'lere Ã§evirip ChromaDB'ye kaydediyoruz\n",
    "- ChromaDB: VektÃ¶r benzerliÄŸi aramasÄ± yapabilen Ã¶zel bir veritabanÄ±\n",
    "\n",
    "**SÃ¼reÃ§:**\n",
    "1. Her chunk â†’ Embedding modeline gÃ¶nderiliyor\n",
    "2. Embedding (vektÃ¶r) + chunk metni + metadata â†’ ChromaDB'ye kaydediliyor\n",
    "3. Toplam 49 chunk veritabanÄ±nda\n",
    "\n",
    "**VeritabanÄ±nda ne var?**\n",
    "```\n",
    "[\n",
    "  {id: 1, text: \"Attention Is...\", vector: [0.2, 0.8, ...], metadata: {page: 0}},\n",
    "  {id: 2, text: \"Transformer...\", vector: [0.3, 0.7, ...], metadata: {page: 1}},\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "**Koleksiyon adÄ±:** \"attention_paper\" (birden fazla koleksiyon olabilir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/6] ChromaDB oluÅŸturuluyor...\n",
      "      49 chunk veritabanÄ±nda\n"
     ]
    }
   ],
   "source": [
    "print(\"[4/6] ChromaDB oluÅŸturuluyor...\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"attention_paper\"\n",
    ")\n",
    "print(f\"      {vectorstore._collection.count()} chunk veritabanÄ±nda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” AdÄ±m 5/6: Retriever (Arama Motoru) YapÄ±landÄ±rma\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- VeritabanÄ±ndan en benzer chunk'larÄ± bulacak bir arama motoru oluÅŸturuyoruz\n",
    "\n",
    "**search_type=\"similarity\":** Benzerlik aramasÄ± yap\n",
    "**search_kwargs={\"k\": 3}:** En benzer **3 chunk** getir\n",
    "\n",
    "**NasÄ±l Ã§alÄ±ÅŸÄ±r?**\n",
    "1. Soru gelir: \"Transformer nedir?\"\n",
    "2. Soru embedding'e Ã§evrilir: [0.25, 0.75, ...]\n",
    "3. VeritabanÄ±ndaki tÃ¼m vektÃ¶rlerle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r (cosine similarity)\n",
    "4. En yÃ¼ksek skor alan 3 chunk dÃ¶ner\n",
    "\n",
    "**Neden k=3?**\n",
    "- Ã‡ok az (k=1): Yeterli bilgi olmayabilir\n",
    "- Ã‡ok fazla (k=10): Gereksiz bilgi ve yavaÅŸ performans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/6] Retriever yapÄ±landÄ±rÄ±lÄ±yor...\n",
      "      Retriever hazÄ±r\n"
     ]
    }
   ],
   "source": [
    "print(\"[5/6] Retriever yapÄ±landÄ±rÄ±lÄ±yor...\")\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "print(\"      Retriever hazÄ±r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— AdÄ±m 6/6: RAG Chain (Pipeline) OluÅŸturma\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- TÃ¼m bileÅŸenleri birleÅŸtirip tam bir RAG zinciri oluÅŸturuyoruz\n",
    "\n",
    "**BileÅŸenler:**\n",
    "1. **LLM:** ChatGroq - Cevap Ã¼reten model\n",
    "2. **Prompt Template:** Modele nasÄ±l davranacaÄŸÄ±nÄ± sÃ¶yleyen ÅŸablon\n",
    "3. **format_docs:** 3 chunk'Ä± birleÅŸtiren yardÄ±mcÄ± fonksiyon\n",
    "4. **RAG Chain:** TÃ¼m akÄ±ÅŸÄ± yÃ¶neten zincir\n",
    "\n",
    "**RAG Chain AkÄ±ÅŸÄ± (LCEL ile):**\n",
    "```\n",
    "Soru: \"Transformer nedir?\"\n",
    "    â†“\n",
    "{\"context\": retriever | format_docs, \"question\": \"Transformer nedir?\"}\n",
    "    â†“ (retriever Ã§alÄ±ÅŸÄ±r)\n",
    "VeritabanÄ±ndan 3 benzer chunk bulunur\n",
    "    â†“ (format_docs Ã§alÄ±ÅŸÄ±r)\n",
    "3 chunk birleÅŸtirilir: \"Chunk1\\n\\nChunk2\\n\\nChunk3\"\n",
    "    â†“ (prompt template doldurulur)\n",
    "\"Sen bir asistansÄ±n... BaÄŸlam: [3 chunk] Soru: Transformer nedir?\"\n",
    "    â†“ (LLM Ã§alÄ±ÅŸÄ±r)\n",
    "Model cevap Ã¼retir\n",
    "    â†“ (StrOutputParser Ã§alÄ±ÅŸÄ±r)\n",
    "String olarak dÃ¶ner: \"Transformer modeli...\"\n",
    "```\n",
    "\n",
    "**LCEL OperatÃ¶rleri:**\n",
    "- `|` : \"sonra\" anlamÄ±na gelir (pipe)\n",
    "- `RunnablePassthrough()`: Veriyi olduÄŸu gibi ilet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/6] RAG chain oluÅŸturuluyor...\n",
      "      RAG pipeline hazÄ±r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[6/6] RAG chain oluÅŸturuluyor...\")\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3,\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "template = \"\"\"Sen bir akademik araÅŸtÄ±rma asistanÄ±sÄ±n. Verilen makale bÃ¶lÃ¼mÃ¼ne gÃ¶re soruyu cevapla.\n",
    "\n",
    "BaÄŸlam:\n",
    "{context}\n",
    "\n",
    "Soru: {question}\n",
    "\n",
    "Kurallar:\n",
    "- Sadece verilen makale iÃ§eriÄŸine dayanarak cevap ver\n",
    "- Cevap bulunamazsa \"Bu bilgi makalede bulunmuyor\" de\n",
    "- TÃ¼rkÃ§e ve aÃ§Ä±k bir dille yaz\n",
    "\n",
    "Cevap:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"      RAG pipeline hazÄ±r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SORULARI\n",
      "\n",
      "SORU 1: Transformer modeli nedir?\n",
      "------------------------------------------------------------\n",
      "CEVAP:\n",
      "Transformer modeli, makalede belirtilen bir dil Ã§evirme modelidir. Ä°ngilizce'den Almanca ve FransÄ±zca'ya Ã§eviri yapabilen bu model, Ã¶nceki state-of-the-art modellere gÃ¶re daha iyi BLEU puanlarÄ±na ulaÅŸÄ±yor ve daha dÃ¼ÅŸÃ¼k bir eÄŸitim maliyeti gerektiriyor. Modelin farklÄ± varyasyonlarÄ± ve hiperparametreleri deÄŸiÅŸtirilerek performansÄ± deÄŸerlendiriliyor. Ancak, Transformer modelinin ayrÄ±ntÄ±lÄ± bir tanÄ±mÄ± veya teknik aÃ§Ä±klamasÄ± makalede bulunmuyor. Sadece modelin performansÄ± ve varyasyonlarÄ± hakkÄ±nda bilgi veriliyor.\n",
      "\n",
      "\n",
      "SORU 2: Self-attention mekanizmasÄ± nasÄ±l Ã§alÄ±ÅŸÄ±r?\n",
      "------------------------------------------------------------\n",
      "CEVAP:\n",
      "Self-attention mekanizmasÄ±, bir dizi iÃ§indeki farklÄ± pozisyonlarÄ± iliÅŸkilendirerek dizi hakkÄ±nda bir temsil oluÅŸturur. Bu, bir dizi iÃ§indeki uzun mesafeli baÄŸÄ±mlÄ±lÄ±klarÄ± Ã¶ÄŸrenmeye yardÄ±mcÄ± olur. Makalede verilen Ã¶rnekte, self-attention mekanizmasÄ±, \"making\" kelimesinin uzak baÄŸÄ±mlÄ±lÄ±ÄŸÄ±nÄ± takip ederek \"making...more difficult\" ifadesini tamamlar. FarklÄ± renkler, farklÄ± attention heads (dikkat baÅŸlÄ±klarÄ±) tarafÄ±ndan temsil edilir. Bu, self-attention mekanizmasÄ±nÄ±n dizi iÃ§indeki farklÄ± pozisyonlar arasÄ±ndaki iliÅŸkileri nasÄ±l kurduÄŸunu gÃ¶sterir.\n",
      "\n",
      "\n",
      "SORU 3: Bu makalede hangi veri setleri kullanÄ±lmÄ±ÅŸ?\n",
      "------------------------------------------------------------\n",
      "CEVAP:\n",
      "Bu makalede, \"newstest2014\" veri seti kullanÄ±lmÄ±ÅŸ. Ã–zellikle, Ä°ngilizce-Almanca (EN-DE) ve Ä°ngilizce-FransÄ±zca (EN-FR) Ã§eviriler iÃ§in bu veri setinin kullanÄ±ldÄ±ÄŸÄ± belirtiliyor.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    \"Transformer modeli nedir?\",\n",
    "    \"Self-attention mekanizmasÄ± nasÄ±l Ã§alÄ±ÅŸÄ±r?\",\n",
    "    \"Bu makalede hangi veri setleri kullanÄ±lmÄ±ÅŸ?\"\n",
    "]\n",
    "\n",
    "print(\"TEST SORULARI\\n\")\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"SORU {i}: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    answer = rag_chain.invoke(question)\n",
    "    \n",
    "    print(\"CEVAP:\")\n",
    "    print(answer)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
