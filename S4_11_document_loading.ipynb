{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DokÃ¼man YÃ¼kleme ve Chunking\n",
    "\n",
    "## ğŸ¯ Bu Kodun AmacÄ±\n",
    "PDF dosyalarÄ±nÄ± yÃ¼klemek ve RAG iÃ§in optimal boyutta parÃ§alara ayÄ±rmak.\n",
    "\n",
    "## Ne YapacaÄŸÄ±z?\n",
    "- **PyPDFLoader** ile \"Attention is All You Need\" makalesini yÃ¼kleyeceÄŸiz\n",
    "- Her sayfanÄ±n iÃ§eriÄŸini ve metadata'sÄ±nÄ± inceleyeceÄŸiz\n",
    "- **RecursiveCharacterTextSplitter** ile farklÄ± chunking stratejileri test edeceÄŸiz\n",
    "- ÃœÃ§ farklÄ± **chunk_size ve overlap** kombinasyonunu karÅŸÄ±laÅŸtÄ±racaÄŸÄ±z\n",
    "- En optimal stratejiyi (1000/100) seÃ§ip chunk Ã¶rneklerini gÃ¶receÄŸiz\n",
    "\n",
    "## Ã‡alÄ±ÅŸtÄ±rma\n",
    "Kod Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda PDF yÃ¼klenir, farklÄ± chunking stratejileri test edilir ve sonuÃ§lar karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ PDF DokÃ¼manÄ±nÄ± YÃ¼kleme\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- \"Attention is All You Need\" makalesini PyPDFLoader ile yÃ¼klÃ¼yoruz\n",
    "- Her sayfa ayrÄ± bir Document objesi olarak yÃ¼klenir\n",
    "\n",
    "**Document nedir?**\n",
    "- `page_content`: SayfanÄ±n metni\n",
    "- `metadata`: Sayfa numarasÄ±, dosya adÄ± gibi bilgiler\n",
    "\n",
    "**SonuÃ§:** 15 sayfalÄ±k PDF â†’ 15 ayrÄ± Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YÃ¼klenen sayfa sayÄ±sÄ±: 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "loader = PyPDFLoader(\"attention_is_all_you_need.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"YÃ¼klenen sayfa sayÄ±sÄ±: {len(documents)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘€ Ä°lk Sayfa Ã–nizlemesi\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- YÃ¼klenen dokÃ¼manÄ±n ilk sayfasÄ±nÄ± inceliyoruz\n",
    "- Metadata bilgilerini gÃ¶rÃ¼ntÃ¼lÃ¼yoruz\n",
    "\n",
    "**Metadata neden Ã¶nemli?**\n",
    "- RAG sisteminde \"Bu bilgi 3. sayfada\" gibi referans verebiliriz\n",
    "- PDF hakkÄ±nda (oluÅŸturma tarihi, yaratÄ±cÄ±) bilgi iÃ§erir\n",
    "\n",
    "**[:400]:** Ä°lk 400 karakteri gÃ¶ster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ä°LK SAYFA Ã–NÄ°ZLEME:\n",
      "------------------------------------------------------------\n",
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswaniâˆ—\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeerâˆ—\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmarâˆ—\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreitâˆ—\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jonesâˆ—\n",
      "G...\n",
      "\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ä°LK SAYFA Ã–NÄ°ZLEME:\")\n",
    "print(\"-\" * 60)\n",
    "print(documents[1].page_content[:400] + \"...\")\n",
    "print(f\"\\nMetadata: {documents[0].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ FarklÄ± Chunking Stratejilerini Test Etme\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- 3 farklÄ± chunk_size ve overlap kombinasyonunu test ediyoruz\n",
    "- Hangisinin daha iyi sonuÃ§ verdiÄŸini karÅŸÄ±laÅŸtÄ±rÄ±yoruz\n",
    "\n",
    "**Parametreler:**\n",
    "- **chunk_size:** Her parÃ§anÄ±n maksimum boyutu (karakter)\n",
    "- **chunk_overlap:** Yan yana parÃ§alar arasÄ±ndaki Ã¶rtÃ¼ÅŸme (karakter)\n",
    "\n",
    "**Stratejiler:**\n",
    "1. **500/50:** KÃ¼Ã§Ã¼k chunk'lar â†’ Ã‡ok sayÄ±da parÃ§a, spesifik bilgi\n",
    "2. **1000/100:** Orta boy â†’ Dengeli (EN POPÃœLER) âœ“\n",
    "3. **1500/150:** BÃ¼yÃ¼k chunk'lar â†’ Az sayÄ±da parÃ§a, geniÅŸ context\n",
    "\n",
    "**Overlap neden Ã¶nemli?**\n",
    "- CÃ¼mleler chunk sÄ±nÄ±rÄ±nda kesilirse anlam kaybolur\n",
    "- Overlap ile Ã¶nemli bilgiler birden fazla chunk'ta yer alÄ±r\n",
    "- Ã–rnek: \"Transformer modelleri\" iki chunk'ta da tam olmalÄ±\n",
    "\n",
    "**avg_length:** Ortalama chunk boyutu = (Toplam karakter) / (Chunk sayÄ±sÄ±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNKING STRATEJÄ°LERÄ°:\n",
      "------------------------------------------------------------\n",
      "Size: 500, Overlap: 50\n",
      "  Chunk sayÄ±sÄ±: 93\n",
      "  Ortalama uzunluk: 433 karakter\n",
      "\n",
      "Size: 1000, Overlap: 100\n",
      "  Chunk sayÄ±sÄ±: 49\n",
      "  Ortalama uzunluk: 853 karakter\n",
      "\n",
      "Size: 1500, Overlap: 150\n",
      "  Chunk sayÄ±sÄ±: 37\n",
      "  Ortalama uzunluk: 1135 karakter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strategies = [\n",
    "    {\"chunk_size\": 500, \"chunk_overlap\": 50},\n",
    "    {\"chunk_size\": 1000, \"chunk_overlap\": 100},\n",
    "    {\"chunk_size\": 1500, \"chunk_overlap\": 150}\n",
    "]\n",
    "\n",
    "print(\"CHUNKING STRATEJÄ°LERÄ°:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for strategy in strategies:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=strategy[\"chunk_size\"],\n",
    "        chunk_overlap=strategy[\"chunk_overlap\"]\n",
    "    )\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    avg_length = sum(len(c.page_content) for c in chunks) / len(chunks)\n",
    "    \n",
    "    print(f\"Size: {strategy['chunk_size']}, Overlap: {strategy['chunk_overlap']}\")\n",
    "    print(f\"  Chunk sayÄ±sÄ±: {len(chunks)}\")\n",
    "    print(f\"  Ortalama uzunluk: {avg_length:.0f} karakter\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Optimal Stratejiyi SeÃ§ip Uygulama\n",
    "\n",
    "**Ne yapÄ±yoruz?**\n",
    "- Test sonuÃ§larÄ±na gÃ¶re **1000/100** stratejisini seÃ§iyoruz\n",
    "- TÃ¼m dokÃ¼manÄ± bu strateji ile chunk'lara bÃ¶lÃ¼yoruz\n",
    "- Ä°lk 2 chunk'Ä± Ã¶rnek olarak gÃ¶steriyoruz\n",
    "\n",
    "**Neden 1000/100?**\n",
    "- âœ… Dengeli chunk sayÄ±sÄ± (49 chunk)\n",
    "- âœ… Yeterli context (her chunk anlamlÄ± bilgi iÃ§eriyor)\n",
    "- âœ… Embedding modelleriyle uyumlu\n",
    "- âœ… RAG performansÄ± iÃ§in ideal (hÄ±z + kalite)\n",
    "\n",
    "**RecursiveCharacterTextSplitter neden \"Recursive\"?**\n",
    "1. Ã–nce paragraf sÄ±nÄ±rlarÄ±nÄ± (\\n\\n) dener\n",
    "2. Yoksa satÄ±r sÄ±nÄ±rlarÄ±nÄ± (\\n) dener\n",
    "3. Yoksa cÃ¼mle sÄ±nÄ±rlarÄ±nÄ± (. ! ?) dener\n",
    "4. Son Ã§are: kelime/karakter seviyesinde bÃ¶ler\n",
    "â†’ **AnlamlÄ±** bÃ¶lme yapar!\n",
    "\n",
    "**enumerate(final_chunks[:2], 1):** Ä°lk 2 chunk'Ä± al, 1'den baÅŸlayarak numaralandÄ±r\n",
    "\n",
    "**Sonraki AdÄ±m:** Bu chunk'lar S4_12'de embedding'lere Ã§evrilip vektÃ¶r veritabanÄ±na kaydedilecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEÃ‡Ä°LEN STRATEJÄ°: 1000/100\n",
      "Toplam chunk: 49\n",
      "\n",
      "Ã–RNEK CHUNK'LAR:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Chunk 1 (Sayfa 0):\n",
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "...\n",
      "\n",
      "Chunk 2 (Sayfa 0):\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more pa...\n"
     ]
    }
   ],
   "source": [
    "final_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "final_chunks = final_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"SEÃ‡Ä°LEN STRATEJÄ°: 1000/100\")\n",
    "print(f\"Toplam chunk: {len(final_chunks)}\\n\")\n",
    "\n",
    "print(\"Ã–RNEK CHUNK'LAR:\")\n",
    "print(\"-\" * 60)\n",
    "for i, chunk in enumerate(final_chunks[:2], 1):\n",
    "    print(f\"\\nChunk {i} (Sayfa {chunk.metadata.get('page', 'N/A')}):\")\n",
    "    print(chunk.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
